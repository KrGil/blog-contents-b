# ì„ í˜•íšŒê·€ì™€ ë¡œì§€ìŠ¤í‹± íšŒê·€



## ì„ í˜•íšŒê·€

ì¢…ì†ë³€ìˆ˜ì™€ ë…ë¦½ë³€ìˆ˜ ì‚¬ì´ì˜ ì„ í˜•ì ì¸ ê´€ê³„ì„±ì„ ì°¾ëŠ” ê²ƒ

ì„±ì ì— ì˜í–¥ì„ ì£¼ëŠ” ìš”ì†Œ[â€˜ì •ë³´â€™]ë¥¼ ð‘‹(ë…ë¦½ ë³€ìˆ˜)ë¼ê³  í•˜ê³ , ì´ ð‘‹ê°’ì— ë”°ë¼ ë³€í•˜ëŠ” â€˜ì„±ì â€™ì„ ð‘¦(ì¢…ì† ë³€ìˆ˜).

### ë‹¨ìˆœ ì„ í˜•íšŒê·€

![image-20230318141138346](/Users/eisen/Documents/Github/blog-contents-b/computer-science/artificial-intelligence/introduction-to-deep-learning/week3.assets/image-20230318141138346.png)

- ë…ë¦½ë³€ìˆ˜ì™€ ì¢…ì†ë³€ìˆ˜ê°€ í•œê°œì”© ìžˆì„ ê²½ìš°
- y = ax + b (xëŠ” ë…ë¦½ë³€ìˆ˜, yëŠ” ì¢…ì†ë³€ìˆ˜)

- ìµœì†Œ ì œê³±ë²•ìœ¼ë¡œ ê°’ì„ êµ¬í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤.

![image-20230318140957341](/Users/eisen/Documents/Github/blog-contents-b/computer-science/artificial-intelligence/introduction-to-deep-learning/week3.assets/image-20230318140957341.png)

![image-20230318141150402](/Users/eisen/Documents/Github/blog-contents-b/computer-science/artificial-intelligence/introduction-to-deep-learning/week3.assets/image-20230318141150402.png)



### ë‹¤ì¤‘ ì„ í˜•íšŒê·€

- 2ê°œ ì´ìƒì˜ ë…ë¦½ë³€ìˆ˜ì™€ ì¢…ì† ë³€ìˆ˜ ìƒì´ì˜ ì„ í˜• íšŒê·€

![image-20230318141238256](/Users/eisen/Documents/Github/blog-contents-b/computer-science/artificial-intelligence/introduction-to-deep-learning/week3.assets/image-20230318141238256.png)





## í•™ìŠµì„ í†µí•œ ì„ í˜•íšŒê·€

### ê²½ì‚¬í•˜ê°•ë²•

í‰ê· ì œê³±ì˜¤ì°¨(Mean Square Error)

- ìŒìˆ˜ë¡œ ì¸í•´
- ë¶ˆì—°ì†ì ì¸ ê°’ì˜ ê²½ìš° ë¯¸ë¶„ì´ ë˜ì§€ ì•ŠëŠ”ë‹¤.
- í‰ê· ì„ ì“°ëŠ” ì´ìœ ëŠ” ì˜¤ì°¨ì˜ í¬ê¸°ê°€ í¬ê²Œë˜ë©´ í•™ìŠµì´ ì¶©ë¶„í•´ì„œ ë‚˜ì˜¨ ìˆ˜ì¹˜ê°€ í°ê²ƒì¸ì§€ ë“±ì„ íŒë‹¨í•˜ê¸° ì–´ë µë‹¤.





## ë¡œì§€ìŠ¤í‹± íšŒê·€(Logistic Regression)

ë¶ˆì—°ì†ì ì¸ ê°’(ì´ì‚°ì ì¸ ê°’)ì„ êµ¬í•  ë•Œ ì‚¬ìš©. - binary.

### Binary Classification



ì—°ì†ì ì¸ ë¶„ë¥˜ë¥¼ í•˜ê¸° ìœ„í•´ì„œ

- OneHot encoding:  0 1 2 3

```
0 1 2 3
0 0 1 0
```



### sigmoid function(ì‹œê·¸ëª¨ì´ë“œ í•¨ìˆ˜)

- ëŒ€í‘œì ì¸ í™œì„± í•¨ìˆ˜(activation function)

### ì†ì‹¤í•¨ìˆ˜

- y ê°€ 0ì¼ ë•Œ y~ê°€ 1ì¼ ë•Œ ê°€ìž¥ í° ì†ì‹¤í•¨ìˆ˜
- yê°€ 1ì¼ ë•Œ y~ê°€ 0ì¼ ë•Œ ê°€ìž¥ í° ì†ì‹¤í•¨ìˆ˜ë¥¼ ê°€ì§€ê²Œ ìˆ˜ì •ì„ í•´ì¤˜ì•¼í•©ë‹ˆë‹¤.

==> cross entropy loss í•¨ìˆ˜ë¥¼ ì‚¬ìš©.

#### Cross 









### words

y: target

y~ or y^: predict

ì“°ë ˆë“œ í™€ë“œ

Onehot encoding: https://wikidocs.net/22647



